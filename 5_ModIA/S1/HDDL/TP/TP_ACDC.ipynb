{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJBnXMeSYrua"
   },
   "source": [
    "# TP Deep Clustering \n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=13dN55x2iT_Y29SRkq4748SxaYLfgt_Kp\" width=\"1200\">\n",
    "\n",
    "\n",
    "L'objectif de ce TP consiste à créer un modèle constitué de plusieurs parties :\n",
    "\n",
    "- Un auto-codeur, pré-entraîné pour apprendre la représentation condensée initiale des jeux de données non étiquetés.\n",
    "- Une couche de clustering empilée sur l'encodeur pour affecter la sortie de l'encodeur à un cluster. Les poids de la couche de clustering sont initialisés avec les centres de cluster de K-Means basés sur l'évaluation actuelle.\n",
    "- Entraîner le modèle de clustering pour affiner la couche de clustering et le codeur conjointement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4qodVrRwYjiH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 09:38:49.411583: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-26 09:38:49.569012: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 09:38:50.211309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Input, Layer, InputSpec,  Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnD4kC-bZsKI"
   },
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1m92te4xYw8l"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.datasets import fashion_mnist # à tester, + complexe que l'ensemble mnist \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Chargement et normalisation (entre 0 et 1) des données de la base de données MNIST/Fashion mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_trainIm = x_train.astype('float32') / 255.\n",
    "x_testIm = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = np.reshape(x_trainIm, (len(x_train), 784))\n",
    "x_test = np.reshape(x_testIm, (len(x_test), 784))\n",
    "\n",
    "# Nombre de classes à trouver\n",
    "n_clusters=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7vOClZQZ14K"
   },
   "source": [
    "# Baseline par clustering classique par kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yXhojNVSZzrT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7e1804676200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7e1804676200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7e1804676200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7e1804676200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7e1804676200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7e18c3e86840>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sara/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "# nombre de chiffres\n",
    "n_digits = len(np.unique(y_test))\n",
    "\n",
    "# Initialisation du Kmeans \n",
    "kmeans = MiniBatchKMeans(n_clusters = n_digits)\n",
    "\n",
    "# Appliquer Kmeans sur base d'apprentissage\n",
    "y_pred_kmeans=kmeans.fit_predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5yPoUPLsZzuK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09795"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score de performance\n",
    "accuracy_score(y_train, y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHR3xgT_aQ_K"
   },
   "source": [
    "## Attribution des étiquettes de cluster\n",
    "\n",
    "La classification K-means est une méthode d'apprentissage automatique non supervisée ; par conséquent, les étiquettes attribuées par notre algorithme KMeans font référence à la classification à laquelle chaque tableau a été attribué, et non à l'entier cible réel. Pour résoudre ce problème, définissons quelques fonctions qui prédiront quel nombre entier correspond à chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dSBL0wdUaQXS"
   },
   "outputs": [],
   "source": [
    "def retrieve_info(cluster_labels,y_train):\n",
    " #Associe l'étiquette la plus probable à chaque groupe dans le modèle KMeans.\n",
    " #Résultats : dictionnaire des clusters associés à chaque étiquette.\n",
    "\n",
    "# Initialisation\n",
    "  reference_labels = np.zeros((len(np.unique(cluster_labels)),1))\n",
    "# Loop pour chaque label \n",
    "  for i in range(len(np.unique(cluster_labels))):\n",
    "    index = np.where(cluster_labels == i,1,0)\n",
    "    num = np.bincount(y_train[index==1]).argmax()\n",
    "    reference_labels[i] = num\n",
    "  return reference_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4IhAEol8aTx2"
   },
   "outputs": [],
   "source": [
    "def correspondance(y_pred_kmeans,y_train):\n",
    "  # Correspondance entre la partition et les classes de la vérité terrain\n",
    "  reference_labels = retrieve_info(y_pred_kmeans,y_train)\n",
    "  number_labels = np.zeros(len(y_pred_kmeans))\n",
    "  for i in range(len(y_pred_kmeans)):\n",
    "    number_labels[i] = reference_labels[y_pred_kmeans[i]]\n",
    "  return number_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoGTGzCVaV0c"
   },
   "outputs": [],
   "source": [
    "# Score de performance sur l'apprentissage après correspondance entre les classes\n",
    "# A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBT0fszCaV2x"
   },
   "outputs": [],
   "source": [
    "# Affichage des données \n",
    "count=2000\n",
    "ListeData = np.random.choice(len(x_test), count)\n",
    "inputs = x_train[ListeData]\n",
    "classes = y_train[ListeData]\n",
    "\n",
    "# Appliquer une réduction de données en 2D via la TSNE\n",
    "# A COMPLETER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FobAgv5a5CX"
   },
   "source": [
    "# Autoencodeur classique à définir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nKZsQiRJaV5J"
   },
   "outputs": [],
   "source": [
    "# Architecture de l'autoencodeur\n",
    "# à coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1QNgs-IbBE4"
   },
   "outputs": [],
   "source": [
    "# Autoencodeur summary\n",
    "# à coder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fB_jczRvbLx6"
   },
   "source": [
    "# Entraînement de l'autoencodeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAobpKqWbB1j"
   },
   "outputs": [],
   "source": [
    "# Entraînement de l'autoencodeur \n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=25,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewgm6MT6bLFJ"
   },
   "outputs": [],
   "source": [
    "# Encoder et décoder quelques chiffres de l'ensemble test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bU_PY4AwbB33"
   },
   "outputs": [],
   "source": [
    "n = 20  # Combien de chiffres nous allons afficher\n",
    "\n",
    "# Afficher l'image reconstruite à partir de l'espace latent après entraînement\n",
    "# À COMPLÉTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKUFAn_Cbazm"
   },
   "outputs": [],
   "source": [
    "# Affichage de l'espace latent par réduction de dimension \n",
    "count=2000\n",
    "inputs = x_train[ListeData]\n",
    "classes = y_train[ListeData]\n",
    "\n",
    "# Récupération des données dans l'espace latent\n",
    "\n",
    "\n",
    "# Réduction de dimension 2D par ACP\n",
    "\n",
    "\n",
    "# Réduction de dimension 2D par la TSNE\n",
    "\n",
    "\n",
    "# Affichage de l'espace latent par ACP et TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9djgkumb5su"
   },
   "outputs": [],
   "source": [
    "# Classification par kmeans de l'espace latent sur l'ensemble d'apprentissage\n",
    "\n",
    "# Initialisation du Kmeans \n",
    "kmeans = MiniBatchKMeans(n_clusters = n_digits)\n",
    "\n",
    "# Affichage\n",
    "inputsTrain = x_train\n",
    "classesTrain = y_train\n",
    "\n",
    "\n",
    "# Kmeans sur base d'apprentissage\n",
    "\n",
    "# Score de performance sur l'apprentissage\n",
    "\n",
    "print(\"Performance de l'autoencodeur : accuracy sur kmeans sur l'espace latent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUtkxlECgS01"
   },
   "source": [
    "## Couche de clustering \n",
    "maintient les centres de cluster $\\mu_j$ comme poids entraînables et projette chaque point intégré $z_i$ en soft label $q_i$ par la distribution $t$ de Student:\n",
    "$$q_{ij}=\\frac{(1+\\|z_i-\\mu_j\\|^2)^{-1}}{\\sum_j(1+\\|z_i-\\mu_j\\|^2)^{-1}}$$\n",
    "où $q_{ij}$ est la $j$ième entrée de $q_i$, représentant la probabilité d'appartenance de $z_i$ au cluster $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4Eyk2q4gSd7"
   },
   "outputs": [],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    La couche de classification convertit l'échantillon d'entrée (caractéristique) en une étiquette souple, c'est-à-dire un vecteur qui représente la probabilité d'appartenance de l'échantillon à chaque groupe.\n",
    "    probabilité d'appartenance de l'échantillon à chaque cluster. La probabilité est calculée avec la distribution t de student.\n",
    "    # Exemple\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters : nombre de clusters.\n",
    "        weights : liste de tableaux Numpy de forme `(n_clusters, n_features)` qui représente les centres de clusters initiaux.\n",
    "        alpha : paramètre de la distribution t de Student. La valeur par défaut est 1.0.\n",
    "    # Forme de l'entrée\n",
    "        Tenseur 2D avec la forme : `(n_samples, n_features)`.\n",
    "    # Forme en sortie\n",
    "        Tenseur 2D avec forme : `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "      \"\"\" Distribution t de student, la même que celle utilisée dans l'algorithme t-SNE.\n",
    "                 q_ij = 1/(1+dist(x_i, u_j)^2), puis normalisation.\n",
    "        Arguments :\n",
    "            inputs : la variable contenant les données, shape=(n_samples, n_features)\n",
    "        Retourne :\n",
    "            q : la distribution t de student, ou des étiquettes souples pour chaque échantillon. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "      q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "      q **= (self.alpha + 1.0) / 2.0\n",
    "      q = K.transpose(K.transpose(q) / K.sum(q, axis=1))\n",
    "      return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b40hUtBgaw3"
   },
   "source": [
    "Définition de la distribution $P$ cible définie comme\n",
    "$$p_{ij}=\\frac{q_{ij}^2/\\sum_i q_{ij}}{\\sum_j (q_{ij}^2/\\sum_i q_{ij})}.$$\n",
    "où $p_{ij}$ est la $j$ième entrée de $p_i$ représentant la probabilité d'appartenance de la donnée $i$ la classe $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvA07UpngORL"
   },
   "outputs": [],
   "source": [
    "# Calcul de la distribution cible\n",
    "def target_distribution(q):\n",
    "  # à compléter\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmHLMHJGgiFm"
   },
   "outputs": [],
   "source": [
    "# Configuration de la couche de clustering\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=clustering_layer)\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss='kld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPMGpa8lgvh5"
   },
   "source": [
    "# Entrainement du modèle avec la couche de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mplhRwqlgire"
   },
   "outputs": [],
   "source": [
    "# paramètres à fixer\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter =4000\n",
    "update_interval = 140\n",
    "batch_size=128\n",
    "index_array = np.arange(x_train.shape[0])\n",
    "tol = 0.005 # seuil pour critère d'arrêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ciuY7MUg0Yz"
   },
   "outputs": [],
   "source": [
    "#Initialisation Kmeans\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(x_train))\n",
    "\n",
    "# récupération des centres de clusters   \n",
    "y_pred_last = np.copy(y_pred)\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(x_train, verbose=0)\n",
    "        p = target_distribution(q)  # mise à jour de la distribution cible p \n",
    "\n",
    "        # evaluation de la performance du clustering \n",
    "        y_pred = q.argmax(1)\n",
    "        if y_train is not None: \n",
    "            y_pred=correspondance(y_pred,y_train)\n",
    "            acc = np.round(accuracy_score(y_train, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('(Iter , acc)  ',(ite, acc), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion - model convergence\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x_train.shape[0])]\n",
    "    loss = model.train_on_batch(x=x_train[idx], y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x_train.shape[0] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQYsr_RYg0bZ"
   },
   "outputs": [],
   "source": [
    "# Affichage de l'impact de cette couche clustering \n",
    "\n",
    "inputs = x_train[ListeData]\n",
    "classes = y_train[ListeData]\n",
    "\n",
    "# TSNE sur espace latent avec kmeans\n",
    "coordsAC_V2 = encoder.predict(inputs)\n",
    "coordsTSNE_V2 = TSNE(n_components=2).fit_transform(coordsAC_V2.reshape(count, -1))\n",
    "\n",
    "\n",
    "fig2= plt.figure(figsize=(30, 10))\n",
    "ax2=plt.subplot(1,3,1)\n",
    "ax2.set_title(\"TSNE sur MNIST\")\n",
    "plt.scatter(coordsTSNE[:, 0], coordsTSNE[:, 1], c=classes,cmap='Paired')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(1,3,2)\n",
    "ax2.set_title(\"tSNE sur espace latent\")\n",
    "plt.scatter(coordsTSNE_AC[:, 0], coordsTSNE_AC[:, 1], c=classes,cmap='Paired')\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(1,3,3)\n",
    "ax2.set_title(\"tSNE après clustering sur espace latent\")\n",
    "plt.scatter(coordsTSNE_V2[:, 0], coordsTSNE_V2[:, 1], c=classes,cmap='Paired')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Db4BioO2iBpx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY-boiaOhSLY"
   },
   "source": [
    "# Passer à la version convolutive de l'autoencodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ccVggPBRg0du"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
