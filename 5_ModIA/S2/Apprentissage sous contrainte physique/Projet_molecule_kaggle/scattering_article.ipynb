{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ase.io import read\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, linear_model, pipeline, model_selection\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (linear_model, model_selection, preprocessing,\n",
    "                     pipeline)\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio.torch import HarmonicScattering3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio.scattering3d.backend.torch_backend \\\n",
    "    import TorchBackend3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio.scattering3d.utils \\\n",
    "    import generate_weighted_sum_of_gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio.datasets import fetch_qm7\n",
    "from kymatio.caching import get_cache_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Chargement des positions et charges ===\n",
    "def extract_features(xyz_path):\n",
    "    atoms = read(xyz_path)\n",
    "    return atoms.get_positions(), atoms.get_atomic_numbers()\n",
    "\n",
    "def load_all_xyz(folder_path, max_atoms=23):\n",
    "    positions_list, charges_list = [], []\n",
    "    xyz_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.xyz')])\n",
    "    for f in xyz_files:\n",
    "        pos, chg = extract_features(os.path.join(folder_path, f))\n",
    "        pos_padded = np.zeros((max_atoms, 3))\n",
    "        chg_padded = np.zeros((max_atoms,))\n",
    "        n_atoms = pos.shape[0]\n",
    "        pos_padded[:n_atoms] = pos\n",
    "        chg_padded[:n_atoms] = chg\n",
    "        positions_list.append(pos_padded)\n",
    "        charges_list.append(chg_padded)\n",
    "    return np.stack(positions_list), np.stack(charges_list)\n",
    "\n",
    "# === Chargement des énergies ===\n",
    "data_dir = \"./\"\n",
    "xyz_dir = os.path.join(data_dir, \"atoms\", \"train\")\n",
    "csv_path = os.path.join(data_dir, \"energies\", \"train.csv\")\n",
    "energies_df = pd.read_csv(csv_path)\n",
    "energies_df[\"id\"] = energies_df[\"id\"].astype(str)\n",
    "energies_df = energies_df.sort_values(\"id\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Chargement des positions ===\n",
    "pos_train, full_charges_train = load_all_xyz(xyz_dir, max_atoms=23)\n",
    "n_molecules = pos_train.shape[0]\n",
    "\n",
    "# === Calcul des charges de valence ===\n",
    "valence_charges = np.zeros_like(full_charges_train)\n",
    "valence_charges += (full_charges_train <= 2) * full_charges_train\n",
    "valence_charges += np.logical_and(full_charges_train > 2, full_charges_train <= 10) * (full_charges_train - 2)\n",
    "valence_charges += np.logical_and(full_charges_train > 10, full_charges_train <= 18) * (full_charges_train - 10)\n",
    "\n",
    "# === Normalisation des positions ===\n",
    "overlapping_precision = 1e-1\n",
    "sigma = 2.0\n",
    "min_dist = np.inf\n",
    "for i in range(n_molecules):\n",
    "    n_atoms = np.sum(full_charges_train[i] != 0)\n",
    "    min_dist = min(min_dist, pdist(pos_train[i, :n_atoms]).min())\n",
    "delta = sigma * np.sqrt(-8 * np.log(overlapping_precision))\n",
    "pos_train *= delta / min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paramètres scattering ===\n",
    "M, N, O = 96, 64, 48\n",
    "grid = np.mgrid[-M//2:-M//2+M, -N//2:-N//2+N, -O//2:-O//2+O]\n",
    "grid = np.fft.ifftshift(grid)\n",
    "J = 4\n",
    "L = 3\n",
    "integral_powers = [0.5, 1.0, 2.0, 3.0, 4.0]\n",
    "scattering = HarmonicScattering3D(J=J, shape=(M, N, O), L=L, sigma_0=sigma, integral_powers=integral_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scattering.to(device)\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [1:24:40<00:00,  6.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# === Boucle de batching ===\n",
    "order_0, orders_1_and_2 = [], []\n",
    "batch_size = 8\n",
    "n_batches = int(np.ceil(n_molecules / batch_size))\n",
    "\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start, end = i * batch_size, min((i + 1) * batch_size, n_molecules)\n",
    "    pos_batch = pos_train[start:end]\n",
    "    full_batch = full_charges_train[start:end]\n",
    "    val_batch = valence_charges[start:end]\n",
    "\n",
    "    full_density = generate_weighted_sum_of_gaussians(grid, pos_batch, full_batch, sigma)\n",
    "    val_density = generate_weighted_sum_of_gaussians(grid, pos_batch, val_batch, sigma)\n",
    "    full_density = torch.from_numpy(full_density).to(device).float()\n",
    "    val_density = torch.from_numpy(val_density).to(device).float()\n",
    "    core_density = full_density - val_density\n",
    "    bond_density = torch.abs(val_density - core_density)\n",
    "\n",
    "    # Order 0\n",
    "    f0 = TorchBackend3D.compute_integrals(full_density, integral_powers)\n",
    "    v0 = TorchBackend3D.compute_integrals(val_density, integral_powers)\n",
    "    c0 = TorchBackend3D.compute_integrals(core_density, integral_powers)\n",
    "    b0 = TorchBackend3D.compute_integrals(bond_density, integral_powers)\n",
    "\n",
    "    # Orders 1 & 2\n",
    "    fs = scattering(full_density)\n",
    "    vs = scattering(val_density)\n",
    "    cs = scattering(core_density)\n",
    "    bs = scattering(bond_density)\n",
    "\n",
    "    # Stack\n",
    "    order_0.append(torch.stack([f0, v0, c0, b0], dim=-1))\n",
    "    orders_1_and_2.append(torch.stack([fs, vs, cs, bs], dim=-1))\n",
    "\n",
    "# === Feature flattening ===\n",
    "order_0_train = torch.cat(order_0, dim=0).cpu().numpy().reshape((n_molecules, -1))\n",
    "orders_1_and_2_train = torch.cat(orders_1_and_2, dim=0).cpu().numpy().reshape((n_molecules, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = 'molecule_L_{}_J_{}_sigma_{}_MNO_{}_powers_{}.npy'.format(\n",
    "        L, J, sigma, (M, N, O), integral_powers)\n",
    "\n",
    "cache_dir = get_cache_dir(\"results/train/\")\n",
    "\n",
    "filename = os.path.join(cache_dir, 'order_0_' + basename)\n",
    "np.save(filename, order_0_train)\n",
    "\n",
    "filename = os.path.join(cache_dir, 'orders_1_and_2' + basename)\n",
    "np.save(filename, orders_1_and_2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test, full_charges_test = load_all_xyz(\"./atoms/test/\", max_atoms=23)\n",
    "n_molecules_test = pos_test.shape[0]\n",
    "\n",
    "# === Calcul des charges de valence ===\n",
    "valence_charges = np.zeros_like(full_charges_test)\n",
    "valence_charges += (full_charges_test <= 2) * full_charges_test\n",
    "valence_charges += np.logical_and(full_charges_test > 2, full_charges_test <= 10) * (full_charges_test - 2)\n",
    "valence_charges += np.logical_and(full_charges_test > 10, full_charges_test <= 18) * (full_charges_test - 10)\n",
    "\n",
    "# === Normalisation des positions ===\n",
    "overlapping_precision = 1e-1\n",
    "sigma = 2.0\n",
    "min_dist = np.inf\n",
    "for i in range(n_molecules_test):\n",
    "    n_atoms = np.sum(full_charges_test[i] != 0)\n",
    "    min_dist = min(min_dist, pdist(pos_test[i, :n_atoms]).min())\n",
    "delta = sigma * np.sqrt(-8 * np.log(overlapping_precision))\n",
    "pos_test *= delta / min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paramètres scattering ===\n",
    "M, N, O = 96, 64, 48\n",
    "grid = np.mgrid[-M//2:-M//2+M, -N//2:-N//2+N, -O//2:-O//2+O]\n",
    "grid = np.fft.ifftshift(grid)\n",
    "J = 4\n",
    "L = 3\n",
    "integral_powers = [0.5, 1.0, 2.0, 3.0, 4.0]\n",
    "scattering = HarmonicScattering3D(J=J, shape=(M, N, O), L=L, sigma_0=sigma, integral_powers=integral_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scattering.to(device)\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [26:34<00:00,  7.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# === Boucle de batching ===\n",
    "order_0, orders_1_and_2 = [], []\n",
    "batch_size = 8\n",
    "n_batches = int(np.ceil(n_molecules_test / batch_size))\n",
    "\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start, end = i * batch_size, min((i + 1) * batch_size, n_molecules_test)\n",
    "    pos_batch = pos_test[start:end]\n",
    "    full_batch = full_charges_test[start:end]\n",
    "    val_batch = valence_charges[start:end]\n",
    "\n",
    "    full_density = generate_weighted_sum_of_gaussians(grid, pos_batch, full_batch, sigma)\n",
    "    val_density = generate_weighted_sum_of_gaussians(grid, pos_batch, val_batch, sigma)\n",
    "    full_density = torch.from_numpy(full_density).to(device).float()\n",
    "    val_density = torch.from_numpy(val_density).to(device).float()\n",
    "    core_density = full_density - val_density\n",
    "    bond_density = torch.abs(val_density - core_density)\n",
    "\n",
    "    # Order 0\n",
    "    f0 = TorchBackend3D.compute_integrals(full_density, integral_powers)\n",
    "    v0 = TorchBackend3D.compute_integrals(val_density, integral_powers)\n",
    "    c0 = TorchBackend3D.compute_integrals(core_density, integral_powers)\n",
    "    b0 = TorchBackend3D.compute_integrals(bond_density, integral_powers)\n",
    "\n",
    "    # Orders 1 & 2\n",
    "    fs = scattering(full_density)\n",
    "    vs = scattering(val_density)\n",
    "    cs = scattering(core_density)\n",
    "    bs = scattering(bond_density)\n",
    "\n",
    "    # Stack\n",
    "    order_0.append(torch.stack([f0, v0, c0, b0], dim=-1))\n",
    "    orders_1_and_2.append(torch.stack([fs, vs, cs, bs], dim=-1))\n",
    "\n",
    "# === Feature flattening ===\n",
    "order_0_test = torch.cat(order_0, dim=0).cpu().numpy().reshape((n_molecules_test, -1))\n",
    "orders_1_and_2_test = torch.cat(orders_1_and_2, dim=0).cpu().numpy().reshape((n_molecules_test, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = 'molecule_L_{}_J_{}_sigma_{}_MNO_{}_powers_{}.npy'.format(\n",
    "        L, J, sigma, (M, N, O), integral_powers)\n",
    "\n",
    "cache_dir = get_cache_dir(\"results/test/\")\n",
    "\n",
    "filename = os.path.join(cache_dir, 'order_0_' + basename)\n",
    "np.save(filename, order_0_test)\n",
    "\n",
    "filename = os.path.join(cache_dir, 'orders_1_and_2' + basename)\n",
    "np.save(filename, orders_1_and_2_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
