{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/sara/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/sara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sara/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sara/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \n",
       "0  Led by Woody, Andy's toys live happily in his ...  \n",
       "1  When siblings Judy and Peter discover an encha...  \n",
       "2  A family wedding reignites the ancient feud be...  \n",
       "3  Cheated on, mistreated and stepped on, the wom...  \n",
       "4  Just when George Banks has recovered from his ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import string\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "df = df[[\"original_title\", \"overview\"]].dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/sara/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class StemTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
    "    def __init__(self):\n",
    "        self.stemmer = SnowballStemmer('english')\n",
    "    def __call__(self, doc):\n",
    "        doc = doc.lower()\n",
    "        return [self.stemmer.stem(t) for t in word_tokenize(re.sub(\"[^a-z' ]\", \"\", doc)) if t not in self.ignore_tokens]\n",
    "\n",
    "tokenizer=StemTokenizer()\n",
    "token_stop = tokenizer(' '.join(stop_words))\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=token_stop, max_features=500, ngram_range=(1,2), tokenizer=tokenizer)\n",
    "bow_matrix_count = vectorizer.fit_transform(df['overview'])\n",
    "df['bow_embedding_count'] = [row.toarray().flatten().tolist() for row in bow_matrix_count]\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=token_stop, max_features=500, ngram_range=(1,2), tokenizer=tokenizer)\n",
    "bow_matrix_tfidf = tfidf.fit_transform(df['overview'])\n",
    "df['bow_embedding_tfidf'] = [row.toarray().flatten().tolist() for row in bow_matrix_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-27 12:39:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2025-05-27 12:39:37--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822,24M  5,12MB/s    in 2m 46s  \n",
      "\n",
      "2025-05-27 12:42:23 (4,97 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Computing GloVe embeddings: 100%|██████████| 44512/44512 [00:00<00:00, 60898.51it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def better_tokenizer(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t.isalpha()] \n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def load_glove_embeddings(path, vocab, embedding_dim):\n",
    "    glove_embeddings = {}\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = torch.tensor([float(val) for val in values[1:]], dtype=torch.float32)\n",
    "            glove_embeddings[word] = vector\n",
    "    weights_matrix = torch.randn(len(vocab), embedding_dim)\n",
    "    for word, idx in vocab.items():\n",
    "        if word in glove_embeddings:\n",
    "            weights_matrix[idx] = glove_embeddings[word]\n",
    "    return glove_embeddings, weights_matrix\n",
    "\n",
    "tokenized_overviews = df['overview'].dropna().map(better_tokenizer)\n",
    "\n",
    "counter = Counter()\n",
    "for tokens in tokenized_overviews:\n",
    "    counter.update(tokens)\n",
    "\n",
    "specials = [\"<unk>\"]\n",
    "itos = specials + [word for word, freq in counter.items() if freq >= 2]\n",
    "stoi = {word: idx for idx, word in enumerate(itos)}\n",
    "\n",
    "embedding_dim = 100\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "glove_embeddings, _ = load_glove_embeddings(glove_path, stoi, embedding_dim)\n",
    "\n",
    "def get_glove_embedding(text_tokens):\n",
    "    vectors = [glove_embeddings[token] for token in text_tokens if token in glove_embeddings]\n",
    "    if not vectors:\n",
    "        return torch.zeros(embedding_dim) \n",
    "    return torch.stack(vectors).mean(dim=0)\n",
    "\n",
    "embeddings = []\n",
    "for tokens in tqdm(tokenized_overviews, desc=\"Computing GloVe embeddings\"):\n",
    "    embeddings.append(get_glove_embedding(tokens))\n",
    "\n",
    "\n",
    "embeddings = [vec.tolist() for vec in embeddings]\n",
    "\n",
    "df['glove_embedding'] = embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistillBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing DistilBERT embeddings: 100%|██████████| 44512/44512 [21:36<00:00, 34.33it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_distilbert_embedding(text, tokenizer, model, device):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return np.zeros(768) \n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "tqdm.pandas(desc=\"Computing DistilBERT embeddings\")\n",
    "df['distilbert_embedding'] = df['overview'].progress_apply(\n",
    "    lambda x: get_distilbert_embedding(x, tokenizer, model, device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>bow_embedding_count</th>\n",
       "      <th>bow_embedding_tfidf</th>\n",
       "      <th>glove_embedding</th>\n",
       "      <th>distilbert_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.020005550235509872, 0.21014796197414398, 0...</td>\n",
       "      <td>[-0.25018153, 0.21354215, 0.24297297, -0.03745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.031650930643081665, 0.23956623673439026, 0....</td>\n",
       "      <td>[-0.23026538, 0.1257016, 0.22299434, -0.009155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.07700946927070618, 0.17933276295661926, 0....</td>\n",
       "      <td>[-0.074448496, -0.116385005, 0.2242134, -0.036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.08693083375692368, 0.11770206689834595, 0.2...</td>\n",
       "      <td>[0.12376749, 0.08408527, 0.4186853, 0.09127326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.05611945316195488, 0.0037858595605939627, 0...</td>\n",
       "      <td>[-0.1709905, -0.09648897, 0.42880845, 0.032393...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                                 bow_embedding_count  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 bow_embedding_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     glove_embedding  \\\n",
       "0  [-0.020005550235509872, 0.21014796197414398, 0...   \n",
       "1  [0.031650930643081665, 0.23956623673439026, 0....   \n",
       "2  [-0.07700946927070618, 0.17933276295661926, 0....   \n",
       "3  [0.08693083375692368, 0.11770206689834595, 0.2...   \n",
       "4  [0.05611945316195488, 0.0037858595605939627, 0...   \n",
       "\n",
       "                                distilbert_embedding  \n",
       "0  [-0.25018153, 0.21354215, 0.24297297, -0.03745...  \n",
       "1  [-0.23026538, 0.1257016, 0.22299434, -0.009155...  \n",
       "2  [-0.074448496, -0.116385005, 0.2242134, -0.036...  \n",
       "3  [0.12376749, 0.08408527, 0.4186853, 0.09127326...  \n",
       "4  [-0.1709905, -0.09648897, 0.42880845, 0.032393...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
